{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linear Regression from Scratch**\n",
    "Welcome to this tutorial, where we'll implement **Linear Regression** along with its optimization algorithms: **Gradient Descent** (Batch) and **Stochastic Gradient Descent (SGD)**. \n",
    "\n",
    "We'll go step-by-step through the theory and Python implementation. While this video focuses on the code, the provided Jupyter Notebook includes detailed explanations and equations for your reference.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Introduction to Linear Regression**\n",
    "Linear Regression is a fundamental algorithm used for predicting a continuous target variable ($y$) based on one or more input features ($x$).\n",
    "\n",
    "### **1.1 Hypothesis Function**\n",
    "The hypothesis function models the relationship between inputs and outputs:\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\dots + \\theta_nx_n\n",
    "$$\n",
    "In vectorized form, it can be written as:\n",
    "$$\n",
    "h_\\theta(x) = X \\cdot \\theta\n",
    "$$\n",
    "Where:\n",
    "- $X$: Matrix of input features ($m \\times n$, where $m$ is the number of examples and $n$ is the number of features).\n",
    "- $\\theta$: Vector of model parameters ($n \\times 1$).\n",
    "\n",
    "### **1.2 Goal of Linear Regression**\n",
    "The goal is to find parameters $\\theta$ that minimize the error between predicted values ($h_\\theta(x)$) and actual values ($y$).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Cost Function**\n",
    "To measure how well the model predicts the target, we use the **Mean Squared Error (MSE)** as the cost function:\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $m$: Number of training examples.\n",
    "- $h_\\theta(x^{(i)})$: Predicted value for the $i$-th example.\n",
    "- $y^{(i)}$: Actual value for the $i$-th example.\n",
    "\n",
    "### **Why Divide by $2m$?**\n",
    "The factor $\\frac{1}{2m}$ simplifies the gradient calculation by canceling the constant when differentiating.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Optimization with Gradient Descent**\n",
    "\n",
    "### **3.1 What is Gradient Descent?**\n",
    "Gradient Descent is an iterative optimization algorithm used to minimize the cost function by adjusting the model parameters ($\\theta$) step by step.\n",
    "\n",
    "### **3.2 Algorithm Steps**\n",
    "1. Initialize parameters $\\theta$ (e.g., to zeros or random values).\n",
    "2. Repeat until convergence:\n",
    "   $$\n",
    "   \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n",
    "   $$\n",
    "   Where:\n",
    "   - $\\alpha$: Learning rate, controlling the size of the update step.\n",
    "   - $\\frac{\\partial J(\\theta)}{\\partial \\theta_j}$: Gradient of the cost function with respect to $\\theta_j$.\n",
    "\n",
    "### **3.3 Gradient Calculation**\n",
    "The partial derivative of the cost function is:\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "### **3.4 Vectorized Gradient Descent Update Rule**\n",
    "For computational efficiency, we use the vectorized form:\n",
    "$$\n",
    "\\theta := \\theta - \\alpha \\cdot \\nabla J(\\theta)\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "\\nabla J(\\theta) = \\frac{1}{m} X^T \\cdot (h_\\theta(X) - y)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Stochastic Gradient Descent (SGD)**\n",
    "\n",
    "### **4.1 What is SGD?**\n",
    "Unlike Batch Gradient Descent, which updates parameters after evaluating all training examples, SGD updates parameters after processing each example. This makes SGD faster but noisier.\n",
    "\n",
    "### **4.2 Algorithm Steps**\n",
    "1. Shuffle the dataset.\n",
    "2. For each training example $(x^{(i)}, y^{(i)})$:\n",
    "   $$\n",
    "   \\theta_j := \\theta_j - \\alpha \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)x_j^{(i)}\n",
    "   $$\n",
    "\n",
    "### **4.3 Comparison with Batch Gradient Descent**\n",
    "- **Batch Gradient Descent**: Processes all $m$ examples to compute a single update.\n",
    "- **Stochastic Gradient Descent**: Processes one example at a time for each update.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Multi-Dimensional Data**\n",
    "So far, we've worked with one-dimensional data. For multi-dimensional data:\n",
    "- $X$ becomes a matrix of shape $m \\times n$.\n",
    "- $\\theta$ becomes a vector of shape $n \\times 1$.\n",
    "- The equations for $h_\\theta(x)$, $J(\\theta)$, and gradients remain consistent.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Visualization and Insights**\n",
    "We'll visualize the data and model predictions to interpret the results. Stay tuned for the implementation in the next sections!\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Additional Resources**\n",
    "For a deeper understanding of the math, watch Andrew Ng's **CS229 Lecture on Linear Regression**:\n",
    "[CS229 Lecture Notes](https://cs229.stanford.edu/notes2023fall/cs229-notes1.pdf)\n",
    "\n",
    "---\n",
    "\n",
    "Thank you for following along! The complete code and detailed explanations are available in the notebook attached below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
